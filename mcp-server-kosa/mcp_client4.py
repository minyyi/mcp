import time
import asyncio
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage
from langchain_mcp_adapters.client import MultiServerMCPClient

load_dotenv()
llm = ChatOpenAI(model="gpt-4o", streaming=True)

# âœ… MCP í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
async def setup_tools():
    client = MultiServerMCPClient({
        "test": {
            "command": "python",
            "args": ["./mcp_server.py"],
            "transport": "stdio",
        }
    })
    return await client.get_tools()

# âœ… ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ with íƒ€ì´ë° ì¶œë ¥
async def process_stream(stream_generator):
    results = []
    try:
        start_time = time.time()

        async for chunk in stream_generator:
            elapsed = time.time() - start_time
            print(f"â±ï¸ {elapsed:.2f}s - received chunk")

            key = list(chunk.keys())[0]

            if key == 'agent':
                msg = chunk['agent']['messages'][0]
                content = msg.content if msg.content else msg.additional_kwargs
                print(f"[agent] {content}")

            elif key == 'tools':
                for msg in chunk['tools']['messages']:
                    print(f"[tools] {msg.content}")

            results.append(chunk)

        total = time.time() - start_time
        print(f"\nâœ… Total processing time: {total:.2f} seconds")
        return results

    except Exception as e:
        print(f"âŒ Error: {e}")
        return results

# âœ… ì—ì´ì „íŠ¸ êµ¬ì„±
def create_agent(tools):
    return create_react_agent(llm, tools)

# âœ… ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
async def main():
    tools = await setup_tools()
    agent = create_agent(tools)

    print("==========RESPONSE===========")
    stream = agent.astream(
        {"messages": [HumanMessage(content="ì—°ë´‰ 5ì²œë§Œì› ê±°ì£¼ìì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì¸ê°€ìš”?")]},
        config={"step_limit": 3}  # âœ… ë°˜ë³µ ì œí•œ
    )

    chunks = await process_stream(stream)

    if chunks:
        final_result = chunks[-1]
        print("\nğŸ“Œ Final result:", final_result)

if __name__ == "__main__":
    asyncio.run(main())
